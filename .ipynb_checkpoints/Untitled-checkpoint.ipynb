{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries necessary for this project\n",
    "import os, sys, pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "\n",
    "# display for this notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "2  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "3  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "4  1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
       "\n",
       "         Date  \n",
       "0  20160217.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dfoff = pd.read_csv('../ali-data/ccf_offline_stage1_train.csv')\n",
    "dftest = pd.read_csv('../ali-data/ccf_offline_stage1_test_revised.csv')\n",
    "\n",
    "dfon = pd.read_csv('../ali-data/ccf_online_stage1_train.csv')\n",
    "\n",
    "dfoff.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1754884 entries, 0 to 1754883\n",
      "Data columns (total 7 columns):\n",
      "User_id          int64\n",
      "Merchant_id      int64\n",
      "Coupon_id        float64\n",
      "Discount_rate    object\n",
      "Distance         float64\n",
      "Date_received    float64\n",
      "Date             float64\n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 93.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dfoff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有优惠券，购买商品条数 776984\n",
      "无优惠券，购买商品条数 0\n",
      "有优惠券，不购买商品条数 0\n",
      "无优惠券，不购买商品条数 0\n"
     ]
    }
   ],
   "source": [
    "print('有优惠券，购买商品条数', dfoff[(dfoff['Date_received'] != 'null') & (pd.notnull(dfoff['Date']))].shape[0])\n",
    "print('无优惠券，购买商品条数', dfoff[(dfoff['Date_received'] == 'null') & (dfoff['Date'] != 'null')].shape[0])\n",
    "print('有优惠券，不购买商品条数', dfoff[(dfoff['Date_received'] != 'null') & (dfoff['Date'] == 'null')].shape[0])\n",
    "print('无优惠券，不购买商品条数', dfoff[(dfoff['Date_received'] == 'null') & (dfoff['Date'] == 'null')].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       nan 0.86666667 0.95       0.9        0.83333333 0.8\n",
      " 0.5        0.85       0.75       0.66666667 0.93333333 0.7\n",
      " 0.6        0.96666667 0.98       0.99       0.975      0.33333333\n",
      " 0.2        0.4       ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ed150912ca69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mdfoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mdftest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdftest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-ed150912ca69>\u001b[0m in \u001b[0;36mprocessData\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# convert distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'null'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5689\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5691\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 534\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             raise ValueError('Cannot convert non-finite values (NA or inf) to '\n\u001b[0m\u001b[1;32m    677\u001b[0m                              'integer')\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# In[] 读入源数据\n",
    "def get_source_data():\n",
    "    # 源数据路径\n",
    "    DataPath = '../ali-data'\n",
    "\n",
    "    # 读入源数据\n",
    "    off_train = pd.read_csv(os.path.join(DataPath, 'ccf_offline_stage1_train.csv'),\n",
    "                            parse_dates=['Date_received', 'Date'])\n",
    "    off_train.columns = ['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance', 'Date_received', 'Date']\n",
    "\n",
    "    on_train = pd.read_csv(os.path.join(DataPath, 'ccf_online_stage1_train.csv'), parse_dates=['Date_received', 'Date'])\n",
    "    on_train.columns = ['User_id', 'Merchant_id', 'Action', 'Coupon_id', 'Discount_rate', 'Date_received', 'Date']\n",
    "\n",
    "    off_test = pd.read_csv(os.path.join(DataPath, 'ccf_offline_stage1_test_revised.csv'), parse_dates=['Date_received'])\n",
    "    off_test.columns = ['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance', 'Date_received']\n",
    "\n",
    "    print(off_train.info())\n",
    "    print(off_train.head(5))\n",
    "    return off_train, on_train, off_test\n",
    "\n",
    "\n",
    "# In[] null,na 特殊处理\n",
    "def null_process_offline(dataset, predict=False):\n",
    "    dataset.Distance.fillna(11, inplace=True)\n",
    "    dataset.Distance = dataset.Distance.astype(int)\n",
    "    dataset.Coupon_id.fillna(0, inplace=True)\n",
    "    dataset.Coupon_id = dataset.Coupon_id.astype(int)\n",
    "    dataset.Date_received.fillna(date_null, inplace=True)\n",
    "\n",
    "    dataset[['discount_rate_x', 'discount_rate_y']] = dataset[dataset.Discount_rate.str.contains(':') == True][\n",
    "        'Discount_rate'].str.split(':', expand=True).astype(int)\n",
    "    dataset['discount_rate'] = 1 - dataset.discount_rate_y / dataset.discount_rate_x\n",
    "    dataset.discount_rate = dataset.discount_rate.fillna(dataset.Discount_rate).astype(float)\n",
    "    if predict:\n",
    "        return dataset\n",
    "    else:\n",
    "        dataset.Date.fillna(date_null, inplace=True)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "def null_process_online(dataset):\n",
    "    dataset.Coupon_id.fillna(0, inplace=True)\n",
    "    # online.Coupon_id = online.Coupon_id.astype(int)\n",
    "    dataset.Date_received.fillna(date_null, inplace=True)\n",
    "    dataset.Date.fillna(date_null, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# In[] 生成交叉训练集\n",
    "def data_process(off_train, on_train, off_test):\n",
    "    # train feature split\n",
    "    # 交叉训练集一：收到券的日期大于4月14日和小于5月14日\n",
    "    time_range = ['2016-04-16', '2016-05-15']\n",
    "    dataset1 = off_train[(off_train.Date_received >= time_range[0]) & (off_train.Date_received <= time_range[1])].copy()\n",
    "    dataset1['label'] = 0\n",
    "    dataset1.loc[\n",
    "        (dataset1.Date != date_null) & (dataset1.Date - dataset1.Date_received <= datetime.timedelta(15)), 'label'] = 1\n",
    "    # 交叉训练集一特征offline：线下数据中领券和用券日期大于1月1日和小于4月13日\n",
    "    time_range_date_received = ['2016-01-01', '2016-03-31']\n",
    "    time_range_date = ['2016-01-01', '2016-04-15']\n",
    "    feature1_off = off_train[(off_train.Date >= time_range_date[0]) & (off_train.Date <= time_range_date[1]) | (\n",
    "            (off_train.Coupon_id == 0) & (off_train.Date_received >= time_range_date_received[0]) & (\n",
    "            off_train.Date_received <= time_range_date_received[1]))]\n",
    "    # 交叉训练集一特征online：线上数据中领券和用券日期大于1月1日和小于4月13日[on_train.date == 'null' to on_train.coupon_id == 0]\n",
    "    feature1_on = on_train[(on_train.Date >= time_range_date[0]) & (on_train.Date <= time_range_date[1]) | (\n",
    "            (on_train.Coupon_id == 0) & (on_train.Date_received >= time_range_date_received[0]) & (\n",
    "            on_train.Date_received <= time_range_date_received[1]))]\n",
    "\n",
    "    # 交叉训练集二：收到券的日期大于5月15日和小于6月15日\n",
    "    time_range = ['2016-05-16', '2016-06-15']\n",
    "    dataset2 = off_train[(off_train.Date_received >= time_range[0]) & (off_train.Date_received <= time_range[1])]\n",
    "    dataset2['label'] = 0\n",
    "    dataset2.loc[\n",
    "        (dataset2.Date != date_null) & (dataset2.Date - dataset2.Date_received <= datetime.timedelta(15)), 'label'] = 1\n",
    "    # 交叉训练集二特征offline：线下数据中领券和用券日期大于2月1日和小于5月14日\n",
    "    time_range_date_received = ['2016-02-01', '2016-04-30']\n",
    "    time_range_date = ['2016-02-01', '2016-05-15']\n",
    "    feature2_off = off_train[(off_train.Date >= time_range_date[0]) & (off_train.Date <= time_range_date[1]) | (\n",
    "            (off_train.Coupon_id == 0) & (off_train.Date_received >= time_range_date_received[0]) & (\n",
    "            off_train.Date_received <= time_range_date_received[1]))]\n",
    "    # 交叉训练集二特征online：线上数据中领券和用券日期大于2月1日和小于5月14日\n",
    "    feature2_on = on_train[(on_train.Date >= time_range_date[0]) & (on_train.Date <= time_range_date[1]) | (\n",
    "            (on_train.Coupon_id == 0) & (on_train.Date_received >= time_range_date_received[0]) & (\n",
    "            on_train.Date_received <= time_range_date_received[1]))]\n",
    "\n",
    "    # 测试集\n",
    "    dataset3 = off_test\n",
    "    # 测试集特征offline :线下数据中领券和用券日期大于3月15日和小于6月30日的\n",
    "    time_range = ['2016-03-16', '2016-06-30']\n",
    "    feature3_off = off_train[((off_train.Date >= time_range[0]) & (off_train.Date <= time_range[1])) | (\n",
    "            (off_train.Coupon_id == 0) & (off_train.Date_received >= time_range[0]) & (\n",
    "            off_train.Date_received <= time_range[1]))]\n",
    "    # 测试集特征online :线上数据中领券和用券日期大于3月15日和小于6月30日的\n",
    "    feature3_on = on_train[((on_train.Date >= time_range[0]) & (on_train.Date <= time_range[1])) | (\n",
    "            (on_train.Coupon_id == 0) & (on_train.Date_received >= time_range[0]) & (\n",
    "            on_train.Date_received <= time_range[1]))]\n",
    "\n",
    "    # get train feature\n",
    "    ProcessDataSet1 = get_features(dataset1, feature1_off, feature1_on)\n",
    "    ProcessDataSet2 = get_features(dataset2, feature2_off, feature2_on)\n",
    "    ProcessDataSet3 = get_features(dataset3, feature3_off, feature3_on)\n",
    "\n",
    "    return ProcessDataSet1, ProcessDataSet2, ProcessDataSet3\n",
    "\n",
    "\n",
    "def get_features(dataset, feature_off, feature_on):\n",
    "    dataset = get_offline_features(dataset, feature_off)\n",
    "    return get_online_features(feature_on, dataset)\n",
    "\n",
    "\n",
    "# In[] 定义获取feature的函数\n",
    "def get_offline_features(X, offline):\n",
    "    # X = X[:1000]\n",
    "\n",
    "    print(len(X), len(X.columns))\n",
    "\n",
    "    temp = offline[offline.Coupon_id != 0]\n",
    "    coupon_consume = temp[temp.Date != date_null]\n",
    "    coupon_no_consume = temp[temp.Date == date_null]\n",
    "\n",
    "    user_coupon_consume = coupon_consume.groupby('User_id')\n",
    "\n",
    "    X['weekday'] = X.Date_received.dt.weekday\n",
    "    X['day'] = X.Date_received.dt.day\n",
    "\n",
    "    # # 距离优惠券消费次数\n",
    "    # temp = coupon_consume.groupby('Distance').size().reset_index(name='distance_0')\n",
    "    # X = pd.merge(X, temp, how='left', on='Distance')\n",
    "    #\n",
    "    # # 距离优惠券不消费次数\n",
    "    # temp = coupon_no_consume.groupby('Distance').size().reset_index(name='distance_1')\n",
    "    # X = pd.merge(X, temp, how='left', on='Distance')\n",
    "    #\n",
    "    # # 距离优惠券领取次数\n",
    "    # X['distance_2'] = X.distance_0 + X.distance_1\n",
    "    #\n",
    "    # # 距离优惠券消费率\n",
    "    # X['distance_3'] = X.distance_0 / X.distance_2\n",
    "\n",
    "    # temp = coupon_consume[coupon_consume.Distance != 11].groupby('Distance').size()\n",
    "    # temp['d4'] = temp.Distance.sum() / len(temp)\n",
    "    # X = pd.merge(X, temp, how='left', on='Distance')\n",
    "\n",
    "    '''user features'''\n",
    "\n",
    "    # 优惠券消费次数\n",
    "    temp = user_coupon_consume.size().reset_index(name='u2')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "    # X.u2.fillna(0, inplace=True)\n",
    "    # X.u2 = X.u2.astype(int)\n",
    "\n",
    "    # 优惠券不消费次数\n",
    "    temp = coupon_no_consume.groupby('User_id').size().reset_index(name='u3')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 使用优惠券次数与没使用优惠券次数比值\n",
    "    X['u19'] = X.u2 / X.u3\n",
    "\n",
    "    # 领取优惠券次数\n",
    "    X['u1'] = X.u2.fillna(0) + X.u3.fillna(0)\n",
    "\n",
    "    # 优惠券核销率\n",
    "    X['u4'] = X.u2 / X.u1\n",
    "\n",
    "    # 普通消费次数\n",
    "    temp = offline[(offline.Coupon_id == 0) & (offline.Date != date_null)]\n",
    "    temp1 = temp.groupby('User_id').size().reset_index(name='u5')\n",
    "    X = pd.merge(X, temp1, how='left', on='User_id')\n",
    "\n",
    "    # 一共消费多少次\n",
    "    X['u25'] = X.u2 + X.u5\n",
    "\n",
    "    # 用户使用优惠券消费占比\n",
    "    X['u20'] = X.u2 / X.u25\n",
    "\n",
    "    # 正常消费平均间隔\n",
    "    temp = pd.merge(temp, temp.groupby('User_id').Date.max().reset_index(name='max'))\n",
    "    temp = pd.merge(temp, temp.groupby('User_id').Date.min().reset_index(name='min'))\n",
    "    temp = pd.merge(temp, temp.groupby('User_id').size().reset_index(name='len'))\n",
    "    temp['u6'] = ((temp['max'] - temp['min']).dt.days / (temp['len'] - 1))\n",
    "    temp = temp.drop_duplicates('User_id')\n",
    "    X = pd.merge(X, temp[['User_id', 'u6']], how='left', on='User_id')\n",
    "\n",
    "    # 优惠券消费平均间隔\n",
    "    temp = pd.merge(coupon_consume, user_coupon_consume.Date.max().reset_index(name='max'))\n",
    "    temp = pd.merge(temp, temp.groupby('User_id').Date.min().reset_index(name='min'))\n",
    "    temp = pd.merge(temp, temp.groupby('User_id').size().reset_index(name='len'))\n",
    "    temp['u7'] = ((temp['max'] - temp['min']).dt.days / (temp['len'] - 1))\n",
    "    temp = temp.drop_duplicates('User_id')\n",
    "    X = pd.merge(X, temp[['User_id', 'u7']], how='left', on='User_id')\n",
    "\n",
    "    # 15天内平均会普通消费几次\n",
    "    X['u8'] = X.u6 / 15\n",
    "\n",
    "    # 15天内平均会优惠券消费几次\n",
    "    X['u9'] = X.u7 / 15\n",
    "\n",
    "    # 领取优惠券到使用优惠券的平均间隔时间\n",
    "    temp = coupon_consume.copy()\n",
    "    temp['days'] = (temp.Date - temp.Date_received).dt.days\n",
    "    temp = (temp.groupby('User_id').days.sum() / temp.groupby('User_id').size()).reset_index(name='u10')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 在15天内使用掉优惠券的值大小\n",
    "    X['u11'] = X.u10 / 15\n",
    "\n",
    "    # 领取优惠券到使用优惠券间隔小于15天的次数\n",
    "    temp = coupon_consume.copy()\n",
    "    temp['days'] = (temp.Date - temp.Date_received).dt.days\n",
    "    temp = temp[temp.days <= 15]\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='u21')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户15天使用掉优惠券的次数除以使用优惠券的次数\n",
    "    X['u22'] = X.u21 / X.u2\n",
    "\n",
    "    # 用户15天使用掉优惠券的次数除以领取优惠券未消费的次数\n",
    "    X['u23'] = X.u21 / X.u3\n",
    "\n",
    "    # 用户15天使用掉优惠券的次数除以领取优惠券的总次数\n",
    "    X['u24'] = X.u21 / X.u1\n",
    "\n",
    "    # 消费优惠券的平均折率\n",
    "    temp = user_coupon_consume.discount_rate.mean().reset_index(name='u45')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销优惠券的最低消费折率\n",
    "    temp = user_coupon_consume.discount_rate.min().reset_index(name='u27')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销优惠券的最高消费折率\n",
    "    temp = user_coupon_consume.discount_rate.max().reset_index(name='u28')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销过的不同优惠券数量\n",
    "    temp = coupon_consume.groupby(['User_id', 'Coupon_id']).size()\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='u32')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户领取所有不同优惠券数量\n",
    "    temp = offline[offline.Date_received != date_null]\n",
    "    temp = temp.groupby(['User_id', 'Coupon_id']).size().reset_index(name='u47')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Coupon_id'])\n",
    "\n",
    "    # 用户核销过的不同优惠券数量占所有不同优惠券的比重\n",
    "    X['u33'] = X.u32 / X.u47\n",
    "\n",
    "    # 用户平均每种优惠券核销多少张\n",
    "    X['u34'] = X.u2 / X.u47\n",
    "\n",
    "    # 核销优惠券用户-商家平均距离\n",
    "    temp = offline[(offline.Coupon_id != 0) & (offline.Date != date_null) & (offline.Distance != 11)]\n",
    "    temp = temp.groupby('User_id').Distance\n",
    "    temp = pd.merge(temp.count().reset_index(name='x'), temp.sum().reset_index(name='y'), on='User_id')\n",
    "    temp['u35'] = temp.y / temp.x\n",
    "    temp = temp[['User_id', 'u35']]\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销优惠券中的最小用户-商家距离\n",
    "    temp = coupon_consume[coupon_consume.Distance != 11]\n",
    "    temp = temp.groupby('User_id').Distance.min().reset_index(name='u36')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销优惠券中的最大用户-商家距离\n",
    "    temp = coupon_consume[coupon_consume.Distance != 11]\n",
    "    temp = temp.groupby('User_id').Distance.max().reset_index(name='u37')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 优惠券类型\n",
    "    discount_types = [\n",
    "        '0.2', '0.5', '0.6', '0.7', '0.75', '0.8', '0.85', '0.9', '0.95', '30:20', '50:30', '10:5',\n",
    "        '20:10', '100:50', '200:100', '50:20', '30:10', '150:50', '100:30', '20:5', '200:50', '5:1',\n",
    "        '50:10', '100:20', '150:30', '30:5', '300:50', '200:30', '150:20', '10:1', '50:5', '100:10',\n",
    "        '200:20', '300:30', '150:10', '300:20', '500:30', '20:1', '100:5', '200:10', '30:1', '150:5',\n",
    "        '300:10', '200:5', '50:1', '100:1',\n",
    "    ]\n",
    "    X['discount_type'] = -1\n",
    "    for k, v in enumerate(discount_types):\n",
    "        X.loc[X.Discount_rate == v, 'discount_type'] = k\n",
    "\n",
    "    # 不同优惠券领取次数\n",
    "    temp = offline.groupby(['User_id', 'Discount_rate']).size().reset_index(name='u41')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Discount_rate'])\n",
    "\n",
    "    # 不同优惠券使用次数\n",
    "    temp = coupon_consume.groupby(['User_id', 'Discount_rate']).size().reset_index(name='u42')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Discount_rate'])\n",
    "\n",
    "    # 不同优惠券不使用次数\n",
    "    temp = coupon_no_consume.groupby(['User_id', 'Discount_rate']).size().reset_index(name='u43')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Discount_rate'])\n",
    "\n",
    "    # 不同打折优惠券使用率\n",
    "    X['u44'] = X.u42 / X.u41\n",
    "\n",
    "    # 满减类型优惠券领取次数\n",
    "    temp = offline[offline.Discount_rate.str.contains(':') == True]\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='u48')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 打折类型优惠券领取次数\n",
    "    temp = offline[offline.Discount_rate.str.contains('\\.') == True]\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='u49')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    '''offline merchant features'''\n",
    "\n",
    "    # 商户消费次数\n",
    "    temp = offline[offline.Date != date_null].groupby('Merchant_id').size().reset_index(name='m0')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券被领取后核销次数\n",
    "    temp = coupon_consume.groupby('Merchant_id').size().reset_index(name='m1')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商户正常消费笔数\n",
    "    X['m2'] = X.m0.fillna(0) - X.m1.fillna(0)\n",
    "\n",
    "    # 商家优惠券被领取次数\n",
    "    temp = offline[offline.Date_received != date_null].groupby('Merchant_id').size().reset_index(name='m3')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券被领取后核销率\n",
    "    X['m4'] = X.m1 / X.m3\n",
    "\n",
    "    # 商家优惠券被领取后不核销次数\n",
    "    temp = coupon_no_consume.groupby('Merchant_id').size().reset_index(name='m7')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商户当天优惠券领取次数\n",
    "    temp = X[X.Date_received != date_null]\n",
    "    temp = temp.groupby(['Merchant_id', 'Date_received']).size().reset_index(name='m5')\n",
    "    X = pd.merge(X, temp, how='left', on=['Merchant_id', 'Date_received'])\n",
    "\n",
    "    # 商户当天优惠券领取人数\n",
    "    temp = X[X.Date_received != date_null]\n",
    "    temp = temp.groupby(['User_id', 'Merchant_id', 'Date_received']).size().reset_index()\n",
    "    temp = temp.groupby(['Merchant_id', 'Date_received']).size().reset_index(name='m6')\n",
    "    X = pd.merge(X, temp, how='left', on=['Merchant_id', 'Date_received'])\n",
    "\n",
    "    # 商家优惠券核销的平均消费折率\n",
    "    temp = coupon_consume.groupby('Merchant_id').discount_rate.mean().reset_index(name='m8')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券核销的最小消费折率\n",
    "    temp = coupon_consume.groupby('Merchant_id').discount_rate.max().reset_index(name='m9')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券核销的最大消费折率\n",
    "    temp = coupon_consume.groupby('Merchant_id').discount_rate.min().reset_index(name='m10')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券核销不同的用户数量\n",
    "    temp = coupon_consume.groupby(['Merchant_id', 'User_id']).size()\n",
    "    temp = temp.groupby('Merchant_id').size().reset_index(name='m11')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券领取不同的用户数量\n",
    "    temp = offline[offline.Date_received != date_null].groupby(['Merchant_id', 'User_id']).size()\n",
    "    temp = temp.groupby('Merchant_id').size().reset_index(name='m12')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 核销商家优惠券的不同用户数量其占领取不同的用户比重\n",
    "    X['m13'] = X.m11 / X.m12\n",
    "\n",
    "    # 商家优惠券平均每个用户核销多少张\n",
    "    X['m14'] = X.m1 / X.m12\n",
    "\n",
    "    # 商家被核销过的不同优惠券数量\n",
    "    temp = coupon_consume.groupby(['Merchant_id', 'Coupon_id']).size()\n",
    "    temp = temp.groupby('Merchant_id').size().reset_index(name='m15')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家领取过的不同优惠券数量的比重\n",
    "    temp = offline[offline.Date_received != date_null].groupby(['Merchant_id', 'Coupon_id']).size()\n",
    "    temp = temp.groupby('Merchant_id').count().reset_index(name='m18')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销过的不同优惠券数量占所有领取过的不同优惠券数量的比重\n",
    "    X['m19'] = X.m15 / X.m18\n",
    "\n",
    "    # 商家被核销优惠券的平均时间\n",
    "    temp = pd.merge(coupon_consume, coupon_consume.groupby('Merchant_id').Date.max().reset_index(name='max'))\n",
    "    temp = pd.merge(temp, temp.groupby('Merchant_id').Date.min().reset_index(name='min'))\n",
    "    temp = pd.merge(temp, temp.groupby('Merchant_id').size().reset_index(name='len'))\n",
    "    temp['m20'] = ((temp['max'] - temp['min']).dt.days / (temp['len'] - 1))\n",
    "    temp = temp.drop_duplicates('Merchant_id')\n",
    "    X = pd.merge(X, temp[['Merchant_id', 'm20']], how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销优惠券中的用户-商家平均距离\n",
    "    temp = coupon_consume[coupon_consume.Distance != 11].groupby('Merchant_id').Distance\n",
    "    temp = pd.merge(temp.count().reset_index(name='x'), temp.sum().reset_index(name='y'), on='Merchant_id')\n",
    "    temp['m21'] = temp.y / temp.x\n",
    "    temp = temp[['Merchant_id', 'm21']]\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销优惠券中的用户-商家最小距离\n",
    "    temp = coupon_consume[coupon_consume.Distance != 11]\n",
    "    temp = temp.groupby('Merchant_id').Distance.min().reset_index(name='m22')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销优惠券中的用户-商家最大距离\n",
    "    temp = coupon_consume[coupon_consume.Distance != 11]\n",
    "    temp = temp.groupby('Merchant_id').Distance.max().reset_index(name='m23')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    \"\"\"offline coupon features\"\"\"\n",
    "\n",
    "    # 此优惠券一共发行多少张\n",
    "    temp = offline[offline.Coupon_id != 0].groupby('Coupon_id').size().reset_index(name='c1')\n",
    "    X = pd.merge(X, temp, how='left', on='Coupon_id')\n",
    "\n",
    "    # 此优惠券一共被使用多少张\n",
    "    temp = coupon_consume.groupby('Coupon_id').size().reset_index(name='c2')\n",
    "    X = pd.merge(X, temp, how='left', on='Coupon_id')\n",
    "\n",
    "    # 优惠券使用率\n",
    "    X['c3'] = X.c2 / X.c1\n",
    "\n",
    "    # 没有使用的数目\n",
    "    X['c4'] = X.c1 - X.c2\n",
    "\n",
    "    # 此优惠券在当天发行了多少张\n",
    "    temp = X.groupby(['Coupon_id', 'Date_received']).size().reset_index(name='c5')\n",
    "    X = pd.merge(X, temp, how='left', on=['Coupon_id', 'Date_received'])\n",
    "\n",
    "    # 优惠券类型(直接优惠为0, 满减为1)\n",
    "    X['c6'] = 0\n",
    "    X.loc[X.Discount_rate.str.contains(':') == True, 'c6'] = 1\n",
    "\n",
    "    # 不同打折优惠券领取次数\n",
    "    temp = offline.groupby('Discount_rate').size().reset_index(name='c8')\n",
    "    X = pd.merge(X, temp, how='left', on='Discount_rate')\n",
    "\n",
    "    # 不同打折优惠券使用次数\n",
    "    temp = coupon_consume.groupby('Discount_rate').size().reset_index(name='c9')\n",
    "    X = pd.merge(X, temp, how='left', on='Discount_rate')\n",
    "\n",
    "    # 不同打折优惠券不使用次数\n",
    "    temp = coupon_no_consume.groupby('Discount_rate').size().reset_index(name='c10')\n",
    "    X = pd.merge(X, temp, how='left', on='Discount_rate')\n",
    "\n",
    "    # 不同打折优惠券使用率\n",
    "    X['c11'] = X.c9 / X.c8\n",
    "\n",
    "    # 优惠券核销平均时间\n",
    "    temp = pd.merge(coupon_consume, coupon_consume.groupby('Coupon_id').Date.max().reset_index(name='max'))\n",
    "    temp = pd.merge(temp, temp.groupby('Coupon_id').Date.min().reset_index(name='min'))\n",
    "    temp = pd.merge(temp, temp.groupby('Coupon_id').size().reset_index(name='count'))\n",
    "    temp['c12'] = ((temp['max'] - temp['min']).dt.days / (temp['count'] - 1))\n",
    "    temp = temp.drop_duplicates('Coupon_id')\n",
    "    X = pd.merge(X, temp[['Coupon_id', 'c12']], how='left', on='Coupon_id')\n",
    "\n",
    "    '''user merchant feature'''\n",
    "\n",
    "    # 用户领取商家的优惠券次数\n",
    "    temp = offline[offline.Coupon_id != 0]\n",
    "    temp = temp.groupby(['User_id', 'Merchant_id']).size().reset_index(name='um1')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户领取商家的优惠券后不核销次数\n",
    "    temp = coupon_no_consume.groupby(['User_id', 'Merchant_id']).size().reset_index(name='um2')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户领取商家的优惠券后核销次数\n",
    "    temp = coupon_consume.groupby(['User_id', 'Merchant_id']).size().reset_index(name='um3')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户领取商家的优惠券后核销率\n",
    "    X['um4'] = X.um3 / X.um1\n",
    "\n",
    "    # 用户对每个商家的不核销次数占用户总的不核销次数的比重\n",
    "    temp = coupon_no_consume.groupby('User_id').size().reset_index(name='temp')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "    X['um5'] = X.um2 / X.temp\n",
    "    X.drop(columns='temp', inplace=True)\n",
    "\n",
    "    # 用户在商店总共消费过几次\n",
    "    temp = offline[offline.Date != date_null].groupby(['User_id', 'Merchant_id']).size().reset_index(name='um6')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户在商店普通消费次数\n",
    "    temp = offline[(offline.Coupon_id == 0) & (offline.Date != date_null)]\n",
    "    temp = temp.groupby(['User_id', 'Merchant_id']).size().reset_index(name='um7')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户当天在此商店领取的优惠券数目\n",
    "    temp = offline[offline.Date_received != date_null]\n",
    "    temp = temp.groupby(['User_id', 'Merchant_id', 'Date_received']).size().reset_index(name='um8')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id', 'Date_received'])\n",
    "\n",
    "    # 用户领取优惠券不同商家数量\n",
    "    temp = offline[offline.Coupon_id == offline.Coupon_id]\n",
    "    temp = temp.groupby(['User_id', 'Merchant_id']).size().reset_index()\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='um9')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销优惠券不同商家数量\n",
    "    temp = coupon_consume.groupby(['User_id', 'Merchant_id']).size()\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='um10')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销过优惠券的不同商家数量占所有不同商家的比重\n",
    "    X['um11'] = X.um10 / X.um9\n",
    "\n",
    "    # 用户平均核销每个商家多少张优惠券\n",
    "    X['um12'] = X.u2 / X.um9\n",
    "\n",
    "    '''other feature'''\n",
    "\n",
    "    # 用户领取的所有优惠券数目\n",
    "    temp = X.groupby('User_id').size().reset_index(name='o1')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户领取的特定优惠券数目\n",
    "    temp = X.groupby(['User_id', 'Coupon_id']).size().reset_index(name='o2')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Coupon_id'])\n",
    "\n",
    "    # multiple threads\n",
    "    # data split\n",
    "    stop = len(X)\n",
    "    step = int(ceil(stop / cpu_jobs))\n",
    "\n",
    "    X_chunks = [X[i:i + step] for i in range(0, stop, step)]\n",
    "    X_list = [X] * cpu_jobs\n",
    "    counters = [i for i in range(cpu_jobs)]\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "    with ProcessPoolExecutor() as e:\n",
    "        X = pd.concat(e.map(task, X_chunks, X_list, counters))\n",
    "        print('time:', str(datetime.datetime.now() - start).split('.')[0])\n",
    "    # multiple threads\n",
    "\n",
    "    # 用户领取优惠券平均时间间隔\n",
    "    temp = pd.merge(X, X.groupby('User_id').Date_received.max().reset_index(name='max'))\n",
    "    temp = pd.merge(temp, temp.groupby('User_id').Date_received.min().reset_index(name='min'))\n",
    "    temp = pd.merge(temp, temp.groupby('User_id').size().reset_index(name='len'))\n",
    "    temp['o7'] = ((temp['max'] - temp['min']).dt.days / (temp['len'] - 1))\n",
    "    temp = temp.drop_duplicates('User_id')\n",
    "    X = pd.merge(X, temp[['User_id', 'o7']], how='left', on='User_id')\n",
    "\n",
    "    # 用户领取特定商家的优惠券数目\n",
    "    temp = X.groupby(['User_id', 'Merchant_id']).size().reset_index(name='o8')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户领取的不同商家数目\n",
    "    temp = X.groupby(['User_id', 'Merchant_id']).size()\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='o9')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户当天领取的优惠券数目\n",
    "    temp = X.groupby(['User_id', 'Date_received']).size().reset_index(name='o10')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Date_received'])\n",
    "\n",
    "    # 用户当天领取的特定优惠券数目\n",
    "    temp = X.groupby(['User_id', 'Coupon_id', 'Date_received']).size().reset_index(name='o11')\n",
    "    X = pd.merge(X, temp, how='left', on=['User_id', 'Coupon_id', 'Date_received'])\n",
    "\n",
    "    # 用户领取的所有优惠券种类数目\n",
    "    temp = X.groupby(['User_id', 'Coupon_id']).size()\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='o12')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 商家被领取的优惠券数目\n",
    "    temp = X.groupby('Merchant_id').size().reset_index(name='o13')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被领取的特定优惠券数目\n",
    "    temp = X.groupby(['Merchant_id', 'Coupon_id']).size().reset_index(name='o14')\n",
    "    X = pd.merge(X, temp, how='left', on=['Merchant_id', 'Coupon_id'])\n",
    "\n",
    "    # 商家被多少不同用户领取的数目\n",
    "    temp = X.groupby(['Merchant_id', 'User_id']).size()\n",
    "    temp = temp.groupby('Merchant_id').size().reset_index(name='o15')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家发行的所有优惠券种类数目\n",
    "    temp = X.groupby(['Merchant_id', 'Coupon_id']).size()\n",
    "    temp = temp.groupby('Merchant_id').size().reset_index(name='o16')\n",
    "    X = pd.merge(X, temp, how='left', on='Merchant_id')\n",
    "\n",
    "    print(len(X), len(X.columns))\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def get_online_features(online, X):\n",
    "    # temp = online[online.Coupon_id == online.Coupon_id]\n",
    "    # coupon_consume = temp[temp.Date == temp.Date]\n",
    "    # coupon_no_consume = temp[temp.Date != temp.Date]\n",
    "\n",
    "    # 用户线上操作次数\n",
    "    temp = online.groupby('User_id').size().reset_index(name='on_u1')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户线上点击次数\n",
    "    temp = online[online.Action == 0].groupby('User_id').size().reset_index(name='on_u2')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户线上点击率\n",
    "    X['on_u3'] = X.on_u2 / X.on_u1\n",
    "\n",
    "    # 用户线上购买次数\n",
    "    temp = online[online.Action == 1].groupby('User_id').size().reset_index(name='on_u4')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户线上购买率\n",
    "    X['on_u5'] = X.on_u4 / X.on_u1\n",
    "\n",
    "    # 用户线上领取次数\n",
    "    temp = online[online.Coupon_id != 0].groupby('User_id').size().reset_index(name='on_u6')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户线上领取率\n",
    "    X['on_u7'] = X.on_u6 / X.on_u1\n",
    "\n",
    "    # 用户线上不消费次数\n",
    "    temp = online[(online.Date == date_null) & (online.Coupon_id != 0)]\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='on_u8')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户线上优惠券核销次数\n",
    "    temp = online[(online.Date != date_null) & (online.Coupon_id != 0)]\n",
    "    temp = temp.groupby('User_id').size().reset_index(name='on_u9')\n",
    "    X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "    # 用户线上优惠券核销率\n",
    "    X['on_u10'] = X.on_u9 / X.on_u6\n",
    "\n",
    "    # 用户线下不消费次数占线上线下总的不消费次数的比重\n",
    "    X['on_u11'] = X.u3 / (X.on_u8 + X.u3)\n",
    "\n",
    "    # 用户线下的优惠券核销次数占线上线下总的优惠券核销次数的比重\n",
    "    X['on_u12'] = X.u2 / (X.on_u9 + X.u2)\n",
    "\n",
    "    # 用户线下领取的记录数量占总的记录数量的比重\n",
    "    X['on_u13'] = X.u1 / (X.on_u6 + X.u1)\n",
    "\n",
    "    # # 消费优惠券的平均折率\n",
    "    # temp = coupon_consume.groupby('User_id').discount_rate.mean().reset_index(name='ou14')\n",
    "    # X = pd.merge(X, temp, how='left', on='User_id')\n",
    "    #\n",
    "    # # 用户核销优惠券的最低消费折率\n",
    "    # temp = coupon_consume.groupby('User_id').discount_rate.min().reset_index(name='ou15')\n",
    "    # X = pd.merge(X, temp, how='left', on='User_id')\n",
    "    #\n",
    "    # # 用户核销优惠券的最高消费折率\n",
    "    # temp = coupon_consume.groupby('User_id').discount_rate.max().reset_index(name='ou16')\n",
    "    # X = pd.merge(X, temp, how='left', on='User_id')\n",
    "    #\n",
    "    # # 不同打折优惠券领取次数\n",
    "    # temp = online.groupby('Discount_rate').size().reset_index(name='oc1')\n",
    "    # X = pd.merge(X, temp, how='left', on='Discount_rate')\n",
    "    #\n",
    "    # # 不同打折优惠券使用次数\n",
    "    # temp = coupon_consume.groupby('Discount_rate').size().reset_index(name='oc2')\n",
    "    # X = pd.merge(X, temp, how='left', on='Discount_rate')\n",
    "    #\n",
    "    # # 不同打折优惠券不使用次数\n",
    "    # temp = coupon_no_consume.groupby('Discount_rate').size().reset_index(name='oc3')\n",
    "    # X = pd.merge(X, temp, how='left', on='Discount_rate')\n",
    "    #\n",
    "    # # 不同打折优惠券使用率\n",
    "    # X['oc4'] = X.oc2 / X.oc1\n",
    "\n",
    "    print(len(X), len(X.columns))\n",
    "    print('----------')\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def task(X_chunk, X, counter):\n",
    "    print(counter, end=',', flush=True)\n",
    "    X_chunk = X_chunk.copy()\n",
    "\n",
    "    X_chunk['o17'] = -1\n",
    "    X_chunk['o18'] = -1\n",
    "\n",
    "    for i, user in X_chunk.iterrows():\n",
    "        temp = X[X.User_id == user.User_id]\n",
    "\n",
    "        temp1 = temp[temp.Date_received < user.Date_received]\n",
    "        temp2 = temp[temp.Date_received > user.Date_received]\n",
    "\n",
    "        # 用户此次之后/前领取的所有优惠券数目\n",
    "        X_chunk.loc[i, 'o3'] = len(temp1)\n",
    "        X_chunk.loc[i, 'o4'] = len(temp2)\n",
    "\n",
    "        # 用户此次之后/前领取的特定优惠券数目\n",
    "        X_chunk.loc[i, 'o5'] = len(temp1[temp1.Coupon_id == user.Coupon_id])\n",
    "        X_chunk.loc[i, 'o6'] = len(temp2[temp2.Coupon_id == user.Coupon_id])\n",
    "\n",
    "        # 用户上/下一次领取的时间间隔\n",
    "        temp1 = temp1.sort_values(by='Date_received', ascending=False)\n",
    "        if len(temp1):\n",
    "            X_chunk.loc[i, 'o17'] = (user.Date_received - temp1.iloc[0].Date_received).days\n",
    "\n",
    "        temp2 = temp2.sort_values(by='Date_received')\n",
    "        if len(temp2):\n",
    "            X_chunk.loc[i, 'o18'] = (temp2.iloc[0].Date_received - user.Date_received).days\n",
    "\n",
    "    return X_chunk\n",
    "\n",
    "\n",
    "# 程序开始时间打印\n",
    "start = datetime.datetime.now()\n",
    "print(start.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "cpu_jobs = os.cpu_count() - 1\n",
    "date_null = pd.to_datetime('1970-01-01', format='%Y-%m-%d')\n",
    "\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# 预处理后数据存放路径\n",
    "FeaturePath = 'data_preprocessed_2'\n",
    "\n",
    "# 读入源数据\n",
    "off_train, on_train, off_test = get_source_data()\n",
    "\n",
    "# 源数据null处理\n",
    "off_train = null_process_offline(off_train, predict=False)\n",
    "on_train = null_process_online(on_train)\n",
    "off_test = null_process_offline(off_test, predict=True)\n",
    "\n",
    "# 获取训练特征集，测试特征集\n",
    "ProcessDataSet1, ProcessDataSet2, ProcessDataSet3 = data_process(off_train, on_train, off_test)\n",
    "\n",
    "# 源数据处理后的数据保存为文件\n",
    "# dataset_1 = get_offline_features(dataset1, feature1_off)\n",
    "# ProcessDataSet1 = get_online_features(feature1_on, dataset_1)\n",
    "ProcessDataSet1.to_csv(os.path.join(FeaturePath, 'ProcessDataSet1.csv'), index=None)\n",
    "\n",
    "# dataset_2 = get_offline_features(dataset2, feature2_off)\n",
    "# ProcessDataSet2 = get_online_features(feature2_on, dataset_2)\n",
    "ProcessDataSet2.to_csv(os.path.join(FeaturePath, 'ProcessDataSet2.csv'), index=None)\n",
    "\n",
    "# dataset_3 = get_offline_features(dataset3, feature3_off)\n",
    "# ProcessDataSet3 = get_online_features(feature3_on, dataset_3)\n",
    "ProcessDataSet3.to_csv(os.path.join(FeaturePath, 'ProcessDataSet3.csv'), index=None)\n",
    "\n",
    "# 花费时间打印\n",
    "print((datetime.datetime.now() - start).seconds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

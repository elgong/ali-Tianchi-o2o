{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  天池新人实战赛o2o优惠券使用预测\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# import os, sys, pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "df_offline = pd.read_csv(\"../ali-data/ccf_offline_stage1_train.csv\")\n",
    "#df_online = pd.read_csv(\"./data/ccf_online_stage1_train.csv\")\n",
    "df_test = pd.read_csv(\"../ali-data/ccf_offline_stage1_test_revised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Merchant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Merchant_id\n",
       "1         4663\n",
       "2         2632\n",
       "3         2632"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# offline 文件\n",
    "df_offline.loc[1:3,[\"Merchant_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    User_id        用户id\n",
    "\n",
    "    Merchant_id     商家id\n",
    "\n",
    "    Coupon_id\t    优惠券id\n",
    "\n",
    "    Discount_rate\t  满x减y\n",
    "\n",
    "    Distance\t    x*500米,user常活动的地点与店铺距离，0：小于500米，10：大于5公里 \n",
    "\n",
    "    Date_received  \t领劵日期\n",
    "\n",
    "    Date          消费日期\n",
    "\n",
    "* 可能用的到的特征是“Discount_rate”“Distance”* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 去掉缺失值22-\n",
    "# df_offline_drop_miss = df_offline[[\"Discount_rate\", \"Distance\"]].dropna()\n",
    "# #df_offline_drop_miss = df_offline.dropna()\n",
    "# #histogram\n",
    "# sns.distplot(df_offline_drop_miss['Distance'])\n",
    "# #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理标签\n",
    "\n",
    "\"Date\" 就是我们要预测的结果，但不是预测日期，而是有没有使用。\n",
    "\n",
    " 不同情况打上不同标签：\n",
    " \n",
    "- 收到优惠卷，未消费： -1\n",
    "- 未收到优惠卷，15天内消费： 0\n",
    "- 收到优惠卷， 消费：  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 合并train 和test，同时做处理\n",
    "data = pd.concat([df_offline, df_test], keys=([\"train\", \"test\"]))\n",
    "\n",
    "#data[\"Date\"] = pd.to_datetime(date[\"Date\"],format=\"%Y%m%d\")\n",
    "#data[\"Date_received\"] = pd.to_datetime(date[\"Date_received\"],format=\"%Y%m%d\")\n",
    "\n",
    "day15 = pd.Timedelta(15,\"D\")\n",
    "def makeLabel(row):\n",
    "    if pd.isnull(row[\"Date_received\"]) : # and pd.isna(row[\"Date\"]) == False:\n",
    "        return -1\n",
    "    elif row[\"Date\"] != \"null\" :\n",
    "        res = pd.to_datetime(row[\"Date\"],format=\"%Y%m%d\") - pd.to_datetime(row[\"Date_received\"],format=\"%Y%m%d\")\n",
    "        if res <= day15:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "data[\"label\"] = data[:].apply(makeLabel, axis=1)\n",
    "data.head()\n",
    "data[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../ali-data/feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../ali-data/feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征\n",
    "\n",
    "### 商户相关特征\n",
    "\n",
    "### 1. 折扣率\n",
    "\n",
    "-  \"Discount_rate\"   满x减y\n",
    "-  用折扣率 1-y/x代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 特征1: 折扣率\n",
    "\n",
    "def rate(x):\n",
    "    x = str(x)\n",
    "    length = len(x)\n",
    "    a=1\n",
    "    b=1\n",
    "    try:\n",
    "        if length == 3:\n",
    "            return 1.0\n",
    "        elif \":\" in x:\n",
    "            a,b = x.split(\":\")\n",
    "            return 1-float(b)/float(a)\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "data[\"f_discount_rate\"] = data[\"Discount_rate\"].apply(lambda x : rate(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 折扣类型\n",
    "\n",
    "-  1 满减\n",
    "-  2 折扣率\n",
    "-  3 无折扣\n",
    "\n",
    "* 然后  ont-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_cls(x):\n",
    "    x = str(x)\n",
    "    length = len(x)\n",
    "    if length == 3:\n",
    "        return 3\n",
    "    elif \":\" in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "data[\"f_discount_cls\"] = data[\"Discount_rate\"].copy()\n",
    "data[\"f_discount_cls\"] = data[\"f_discount_cls\"].apply(lambda x : discount_cls(x))\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# ohe = OneHotEncoder(categorical_features=[0])\n",
    "# ohe.fit_transform(data[\"f_discount_cls\"])\n",
    "data[[\"f_cls_man_jian\", \"f_cls_discount\",\"f_cls_None\"]]=pd.get_dummies(data[\"f_discount_cls\"])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 活动力度\n",
    "\n",
    "分级：\n",
    "\n",
    "- 无活动      0\n",
    "    \n",
    "- 0～10      1\n",
    "    \n",
    "- 10～100    2\n",
    "    \n",
    "- 100～1000  3\n",
    "    \n",
    "- 折扣率      3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Activity_intensity(x):\n",
    "    \n",
    "    if pd.isnull(x):\n",
    "        return 0\n",
    "    x = str(x)\n",
    "    length = len(x)\n",
    "    a=1\n",
    "    b=1\n",
    "\n",
    "    if \":\" in x:\n",
    "        a,b = x.split(\":\")\n",
    "        b=int(b)\n",
    "        \n",
    "        if b < 10:\n",
    "            return 1.0\n",
    "        elif b < 100:\n",
    "            return 2.0\n",
    "        return 3.0\n",
    "    else:\n",
    "        return 3.0\n",
    "        \n",
    "    \n",
    "data[\"f_activity_intensity_x\"] = data[\"Discount_rate\"].apply(lambda x : Activity_intensity(x))\n",
    "data[\"f_activity_intensity_x\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 消费者\n",
    "\n",
    "### 1. 购物次数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = user_coupon_consume.size().reset_index(name='u2')\n",
    "X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "\n",
    "user_id_data = data[data[\"Date\"] != \"null\"][[\"User_id\"]].copy()\n",
    "\n",
    "user_id_data[\"f_count\"] = 1\n",
    "\n",
    "User = user_id_data.groupby([\"User_id\"], as_index = False ).count()\n",
    "\n",
    "data2 = pd.merge(data, User, on = \"User_id\", how = \"left\")\n",
    "data2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 优惠卷使用率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆开数据, 选择特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆开数据\n",
    "# train_data=data.xs('train')\n",
    "# test_data=data.xs('test')#.drop(labels='label',axis=1)\n",
    "train_data = data2[data2.iloc[:,1]== \"train\"]\n",
    "train_data = train_data.iloc[:,3:]\n",
    "\n",
    "test_data = data2[data2.iloc[:,1]== \"test\"]\n",
    "test_data = test_data.iloc[:,3:]\n",
    "\n",
    "\n",
    "train_data = train_data.drop([\"Date\",\"Date_received\",\"Discount_rate\",\"Coupon_id\",\n",
    "                              \"Merchant_id\",\"User_id\",\n",
    "                             ], axis=1)\n",
    "                           \n",
    "train_data = train_data.fillna(0)\n",
    "test_data = test_data.drop([\"Date\",\"Date_received\",\"Discount_rate\",\"Coupon_id\",\n",
    "                            \"Merchant_id\",\"User_id\",\n",
    "                           ], axis=1)\n",
    "\n",
    "x_test = test_data.fillna(0)\n",
    "\n",
    "# 打乱数据\n",
    "# train_data = train_data.sample(frac=1.0)\n",
    "# test_data = x_test.sample(frac=1.0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.sort_values([\"label\"],inplace=True)\n",
    "\n",
    "train_data = train_data[900000:]\n",
    "train_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train_data.head()\n",
    "\n",
    "\n",
    "## 删除  普通消费\n",
    "train_data = train_data[(train_data[\"label\"] != -1)]\n",
    "print(train_data[\"label\"].unique())\n",
    "\n",
    "train_label = train_data[\"label\"]\n",
    "train_data = train_data.drop(\"label\", axis=1)\n",
    "\n",
    "\n",
    "train_data,val_data, train_label ,val_label = train_test_split(train_data,train_label,test_size=0.3,random_state=6)\n",
    "\n",
    "print(\"划分后\")\n",
    "print(\"train %d : 验证 %d\"%(len(train_label),len(val_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(train_label)\n",
    "\n",
    "tmp[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练集，验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "S=StandardScaler()\n",
    "\n",
    "S.fit(train_data)\n",
    "\n",
    "x_train_stand = S.transform(train_data)\n",
    "\n",
    "x_val_stand = S.transform(val_data)\n",
    "\n",
    "\n",
    "print(x_train_stand[1])\n",
    "x_test_stand=S.transform(test_data.drop([\"label\"],axis=1))\n",
    "\n",
    "\n",
    "print(\"----train-----\")\n",
    "model = SGDClassifier(#lambda:\n",
    "    loss='log',\n",
    "    penalty='elasticnet',\n",
    "    fit_intercept=True,\n",
    "    max_iter=100,\n",
    "    shuffle=True,\n",
    "    alpha = 0.01,\n",
    "    l1_ratio = 0.01,\n",
    "    n_jobs=1,\n",
    "    class_weight=None\n",
    ")\n",
    "model.fit(x_train_stand, train_label)\n",
    "print(\"end\")\n",
    "# fpr, tpr, thresholds = roc_curve(val_label, prediction[:,1], pos_label=1)\n",
    "# print(\"auc:\",auc(fpr, tpr))\n",
    "\n",
    "\n",
    "# auc_score1 = myAUC(val_label,prediction[:,0])\n",
    "\n",
    "# print(Log.score(x_val_stand,val_label))\n",
    "# print(auc_score1)\n",
    "\n",
    "# result=pd.DataFrame({'PassengerId':test_data.index,'Survived':res[:,0]})  #这里需要注意把prediction的数据转换成Int型不然系统判定不了，得分会为0 \n",
    "# result.to_csv('../ali-data/result.csv',index=False) #设置不输出Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 预测以及结果评价\n",
    "print(model.score(x_val_stand, val_label))\n",
    "\n",
    "# val = val_data.copy()\n",
    "# val['pred_prob'] = model.predict_proba(x_val_stand)[:,1]\n",
    "# validgroup = val.groupby(['Coupon_id'])\n",
    "# aucs = []\n",
    "# for i in validgroup:\n",
    "#     tmpdf = i[1] \n",
    "#     if len(tmpdf['label'].unique()) != 2:\n",
    "#         continue\n",
    "#     fpr, tpr, thresholds = roc_curve(tmpdf['label'], tmpdf['pred_prob'], pos_label=1)\n",
    "#     aucs.append(auc(fpr, tpr))\n",
    "# print(np.average(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre = model.predict_proba(x_test_stand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction for submission\n",
    "y_test_pred = model.predict_proba(x_test_stand)\n",
    "dftest1 = df_test[['User_id','Coupon_id','Date_received']].copy()\n",
    "dftest1['label'] = y_test_pred[:,1]\n",
    "dftest1.to_csv('../ali-data/submit1.csv', index=False, header=False)\n",
    "dftest1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dftest1 = df_test[['User_id','Coupon_id','Date_received']].copy()\n",
    "dftest1['label'] = res[:,1]\n",
    "dftest1.to_csv('../ali-data/submit1.csv', index=False, header=False)\n",
    "dftest1.head(10)\n",
    "\n",
    "# avgAUC calculation\n",
    "vg = dftest1.groupby(['Coupon_id'])\n",
    "aucs = []\n",
    "for i in vg:\n",
    "    tmpdf = i[1] \n",
    "    if len(tmpdf['label'].unique()) != 2:\n",
    "        continue\n",
    "    fpr, tpr, thresholds = roc_curve(tmpdf['label'], tmpdf['pred_prob'], pos_label=1)\n",
    "    aucs.append(auc(fpr, tpr))\n",
    "print(np.average(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from math import ceil\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "\n",
    "\n",
    "def train_xgb(dataset12, dataset3):\n",
    "    predict_dataset = dataset3[['User_id', 'Coupon_id', 'Date_received']].copy()\n",
    "    predict_dataset.Date_received = pd.to_datetime(predict_dataset.Date_received, format='%Y-%m-%d')\n",
    "    predict_dataset.Date_received = predict_dataset.Date_received.dt.strftime('%Y%m%d')\n",
    "\n",
    "    # 将数据转化为dmatric格式\n",
    "    dataset12_x = dataset12.drop(\n",
    "        columns=['User_id', 'Merchant_id', 'Discount_rate', 'Date_received', 'discount_rate_x', 'discount_rate_y',\n",
    "                 'Date', 'Coupon_id', 'label'], axis=1)\n",
    "    dataset3_x = dataset3.drop(\n",
    "        columns=['User_id', 'Merchant_id', 'Discount_rate', 'Date_received', 'discount_rate_x', 'discount_rate_y',\n",
    "                 'Coupon_id'], axis=1)\n",
    "\n",
    "    train_dmatrix = xgb.DMatrix(dataset12_x, label=dataset12.label)\n",
    "    predict_dmatrix = xgb.DMatrix(dataset3_x)\n",
    "\n",
    "    # xgboost模型训练\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective': 'binary:logistic',\n",
    "              'eval_metric': 'auc',\n",
    "              'gamma': 0.1,\n",
    "              'min_child_weight': 1.1,\n",
    "              'max_depth': 5,\n",
    "              'lambda': 10,\n",
    "              'subsample': 0.7,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'colsample_bylevel': 0.7,\n",
    "              'eta': 0.01,\n",
    "            #   'tree_method': 'gpu_hist',\n",
    "            #   'n_gpus': '-1',\n",
    "              'seed': 0,\n",
    "              'nthread': cpu_jobs,\n",
    "            #   'predictor': 'gpu_predictor'\n",
    "              }\n",
    "\n",
    "    # 使用xgb.cv优化num_boost_round参数\n",
    "    cvresult = xgb.cv(params, train_dmatrix, num_boost_round=10000, nfold=2, metrics='auc', seed=0, callbacks=[\n",
    "        xgb.callback.print_evaluation(show_stdv=False),\n",
    "        xgb.callback.early_stop(50)\n",
    "    ])\n",
    "    num_round_best = cvresult.shape[0] - 1\n",
    "    print('Best round num: ', num_round_best)\n",
    "\n",
    "    # 使用优化后的num_boost_round参数训练模型\n",
    "    watchlist = [(train_dmatrix, 'train')]\n",
    "    model = xgb.train(params, train_dmatrix, num_boost_round=num_round_best, evals=watchlist)\n",
    "\n",
    "    model.save_model('./2xgbmodel')\n",
    "    params['predictor'] = 'cpu_predictor'\n",
    "    model = xgb.Booster(params)\n",
    "    model.load_model('./1xgbmodel')\n",
    "\n",
    "    # predict test set\n",
    "    dataset3_predict = predict_dataset.copy()\n",
    "    dataset3_predict['label'] = model.predict(predict_dmatrix)\n",
    "\n",
    "    # 标签归一化\n",
    "    dataset3_predict.label = MinMaxScaler(copy=True, feature_range=(0, 1)).fit_transform(\n",
    "        dataset3_predict.label.values.reshape(-1, 1))\n",
    "    dataset3_predict.sort_values(by=['Coupon_id', 'label'], inplace=True)\n",
    "    dataset3_predict.to_csv(\"./xgb_preds.csv\", index=None, header=None)\n",
    "    print(dataset3_predict.describe())\n",
    "\n",
    "    # 在dataset12上计算auc\n",
    "    # model = xgb.Booster()\n",
    "    # model.load_model('train_dir_2/xgbmodel')\n",
    "\n",
    "#     temp = dataset12[['Coupon_id', 'label']].copy()\n",
    "#     temp['pred'] = model.predict(xgb.DMatrix(dataset12_x))\n",
    "#     temp.pred = MinMaxScaler(copy=True, feature_range=(0, 1)).fit_transform(temp['pred'].values.reshape(-1, 1))\n",
    "#     print(myauc(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

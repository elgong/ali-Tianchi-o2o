{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  天池新人实战赛o2o优惠券使用预测\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# import os, sys, pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "df_offline = pd.read_csv(\"../ali-data/ccf_offline_stage1_train.csv\")\n",
    "#df_online = pd.read_csv(\"./data/ccf_online_stage1_train.csv\")\n",
    "df_test = pd.read_csv(\"../ali-data/ccf_offline_stage1_test_revised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Merchant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Merchant_id\n",
       "1         4663\n",
       "2         2632\n",
       "3         2632"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# offline 文件\n",
    "df_offline.loc[1:3,[\"Merchant_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    User_id        用户id\n",
    "\n",
    "    Merchant_id     商家id\n",
    "\n",
    "    Coupon_id\t    优惠券id\n",
    "\n",
    "    Discount_rate\t  满x减y\n",
    "\n",
    "    Distance\t    x*500米,user常活动的地点与店铺距离，0：小于500米，10：大于5公里 \n",
    "\n",
    "    Date_received  \t领劵日期\n",
    "\n",
    "    Date          消费日期\n",
    "\n",
    "* 可能用的到的特征是“Discount_rate”“Distance”* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 去掉缺失值22-\n",
    "# df_offline_drop_miss = df_offline[[\"Discount_rate\", \"Distance\"]].dropna()\n",
    "# #df_offline_drop_miss = df_offline.dropna()\n",
    "# #histogram\n",
    "# sns.distplot(df_offline_drop_miss['Distance'])\n",
    "# #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理标签\n",
    "\n",
    "\"Date\" 就是我们要预测的结果，但不是预测日期，而是有没有使用。\n",
    "\n",
    " 不同情况打上不同标签：\n",
    " \n",
    "- 收到优惠卷，未消费： -1\n",
    "- 未收到优惠卷，15天内消费： 0\n",
    "- 收到优惠卷， 消费：  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并train 和test，同时做处理\n",
    "data = pd.concat([df_offline, df_test], keys=([\"train\", \"test\"]))\n",
    "\n",
    "#data[\"Date\"] = pd.to_datetime(date[\"Date\"],format=\"%Y%m%d\")\n",
    "#data[\"Date_received\"] = pd.to_datetime(date[\"Date_received\"],format=\"%Y%m%d\")\n",
    "\n",
    "day15 = pd.Timedelta(15,\"D\")\n",
    "def makeLabel(row):\n",
    "    if pd.isnull(row[\"Date_received\"]) : # and pd.isna(row[\"Date\"]) == False:\n",
    "        return -1\n",
    "    elif row[\"Date\"] != \"null\" :\n",
    "        res = pd.to_datetime(row[\"Date\"],format=\"%Y%m%d\") - pd.to_datetime(row[\"Date_received\"],format=\"%Y%m%d\")\n",
    "        if res <= day15:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "data[\"label\"] = data[:].apply(makeLabel, axis=1)\n",
    "data.head()\n",
    "data[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-021e3dd98191>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../ali-data/feature.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    310\u001b[0m                                         \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                                         \u001b[0mdate_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                                         quoting=self.quoting)\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         libwriters.write_csv_rows(self.data, ix, self.nlevels,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mto_native_types\u001b[1;34m(self, slicer, **kwargs)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mslicer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_native_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_format_native_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m_format_native_types\u001b[1;34m(self, na_rep, **kwargs)\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[1;31m# go through the levels and format them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel_codes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m             \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_native_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mna_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_rep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m             \u001b[1;31m# add nan values, if there are any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlevel_codes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_format_native_types\u001b[1;34m(self, na_rep, quoting, **kwargs)\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m         \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_rep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data.to_csv(\"../ali-data/feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../ali-data/feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>User_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2632</td>\n",
       "      <td>1439408</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>1439408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2632</td>\n",
       "      <td>1439408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2632</td>\n",
       "      <td>1439408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2632</td>\n",
       "      <td>1439408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  Unnamed: 1  Coupon_id        Date  Date_received Discount_rate  \\\n",
       "0      train           0        NaN  20160217.0            NaN           NaN   \n",
       "1      train           1    11002.0         NaN     20160528.0        150:20   \n",
       "2      train           2     8591.0         NaN     20160217.0          20:1   \n",
       "3      train           3     1078.0         NaN     20160319.0          20:1   \n",
       "4      train           4     8591.0         NaN     20160613.0          20:1   \n",
       "\n",
       "   Distance  Merchant_id  User_id  label  \n",
       "0       0.0         2632  1439408     -1  \n",
       "1       1.0         4663  1439408      0  \n",
       "2       0.0         2632  1439408      0  \n",
       "3       0.0         2632  1439408      0  \n",
       "4       0.0         2632  1439408      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征\n",
    "\n",
    "### 商户相关特征\n",
    "\n",
    "### 1. 折扣率\n",
    "\n",
    "-  \"Discount_rate\"   满x减y\n",
    "-  用折扣率 1-y/x代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 特征1: 折扣率\n",
    "\n",
    "def rate(x):\n",
    "    x = str(x)\n",
    "    length = len(x)\n",
    "    a=1\n",
    "    b=1\n",
    "    try:\n",
    "        if length == 3:\n",
    "            return 1.0\n",
    "        elif \":\" in x:\n",
    "            a,b = x.split(\":\")\n",
    "            return 1-float(b)/float(a)\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "data[\"f_discount_rate\"] = data[\"Discount_rate\"].apply(lambda x : rate(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 折扣类型\n",
    "\n",
    "-  1 满减\n",
    "-  2 折扣率\n",
    "-  3 无折扣\n",
    "\n",
    "* 然后  ont-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>User_id</th>\n",
       "      <th>label</th>\n",
       "      <th>f_discount_rate</th>\n",
       "      <th>f_discount_cls</th>\n",
       "      <th>f_cls_man_jian</th>\n",
       "      <th>f_cls_discount</th>\n",
       "      <th>f_cls_None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2632</td>\n",
       "      <td>1439408</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>1439408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2632</td>\n",
       "      <td>1439408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2632</td>\n",
       "      <td>1439408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2632</td>\n",
       "      <td>1439408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  Unnamed: 1  Coupon_id        Date  Date_received Discount_rate  \\\n",
       "0      train           0        NaN  20160217.0            NaN           NaN   \n",
       "1      train           1    11002.0         NaN     20160528.0        150:20   \n",
       "2      train           2     8591.0         NaN     20160217.0          20:1   \n",
       "3      train           3     1078.0         NaN     20160319.0          20:1   \n",
       "4      train           4     8591.0         NaN     20160613.0          20:1   \n",
       "\n",
       "   Distance  Merchant_id  User_id  label  f_discount_rate  f_discount_cls  \\\n",
       "0       0.0         2632  1439408     -1         1.000000               3   \n",
       "1       1.0         4663  1439408      0         0.866667               1   \n",
       "2       0.0         2632  1439408      0         0.950000               1   \n",
       "3       0.0         2632  1439408      0         0.950000               1   \n",
       "4       0.0         2632  1439408      0         0.950000               1   \n",
       "\n",
       "   f_cls_man_jian  f_cls_discount  f_cls_None  \n",
       "0               0               0           1  \n",
       "1               1               0           0  \n",
       "2               1               0           0  \n",
       "3               1               0           0  \n",
       "4               1               0           0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discount_cls(x):\n",
    "    x = str(x)\n",
    "    length = len(x)\n",
    "    if length == 3:\n",
    "        return 3\n",
    "    elif \":\" in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "data[\"f_discount_cls\"] = data[\"Discount_rate\"].copy()\n",
    "data[\"f_discount_cls\"] = data[\"f_discount_cls\"].apply(lambda x : discount_cls(x))\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# ohe = OneHotEncoder(categorical_features=[0])\n",
    "# ohe.fit_transform(data[\"f_discount_cls\"])\n",
    "data[[\"f_cls_man_jian\", \"f_cls_discount\",\"f_cls_None\"]]=pd.get_dummies(data[\"f_discount_cls\"])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 活动力度\n",
    "\n",
    "分级：\n",
    "\n",
    "- 无活动      0\n",
    "    \n",
    "- 0～10      1\n",
    "    \n",
    "- 10～100    2\n",
    "    \n",
    "- 100～1000  3\n",
    "    \n",
    "- 折扣率      3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1., 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def Activity_intensity(x):\n",
    "    \n",
    "    if pd.isnull(x):\n",
    "        return 0\n",
    "    x = str(x)\n",
    "    length = len(x)\n",
    "    a=1\n",
    "    b=1\n",
    "\n",
    "    if \":\" in x:\n",
    "        a,b = x.split(\":\")\n",
    "        b=int(b)\n",
    "        \n",
    "        if b < 10:\n",
    "            return 1.0\n",
    "        elif b < 100:\n",
    "            return 2.0\n",
    "        return 3.0\n",
    "    else:\n",
    "        return 3.0\n",
    "        \n",
    "    \n",
    "data[\"f_activity_intensity_x\"] = data[\"Discount_rate\"].apply(lambda x : Activity_intensity(x))\n",
    "data[\"f_activity_intensity_x\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 消费者\n",
    "\n",
    "### 1. 购物次数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_coupon_consume' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2ac0004f3edc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_coupon_consume\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'u2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'User_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0muser_id_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"null\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"User_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_coupon_consume' is not defined"
     ]
    }
   ],
   "source": [
    "temp = user_coupon_consume.size().reset_index(name='u2')\n",
    "X = pd.merge(X, temp, how='left', on='User_id')\n",
    "\n",
    "\n",
    "user_id_data = data[data[\"Date\"] != \"null\"][[\"User_id\"]].copy()\n",
    "\n",
    "user_id_data[\"f_count\"] = 1\n",
    "\n",
    "User = user_id_data.groupby([\"User_id\"], as_index = False ).count()\n",
    "\n",
    "data2 = pd.merge(data, User, on = \"User_id\", how = \"left\")\n",
    "data2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 优惠卷使用率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆开数据, 选择特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆开数据\n",
    "# train_data=data.xs('train')\n",
    "# test_data=data.xs('test')#.drop(labels='label',axis=1)\n",
    "train_data = data2[data2.iloc[:,1]== \"train\"]\n",
    "train_data = train_data.iloc[:,3:]\n",
    "\n",
    "test_data = data2[data2.iloc[:,1]== \"test\"]\n",
    "test_data = test_data.iloc[:,3:]\n",
    "\n",
    "\n",
    "# train_data = train_data.drop([\"Date\",\"Date_received\",\"Discount_rate\",\"Coupon_id\",\n",
    "#                               \"Merchant_id\",\"User_id\",\n",
    "#                              ], axis=1)\n",
    "                           \n",
    "train_data = train_data.fillna(0)\n",
    "# test_data = test_data.drop([\"Date\",\"Date_received\",\"Discount_rate\",\"Coupon_id\",\n",
    "#                             \"Merchant_id\",\"User_id\",\n",
    "#                            ], axis=1)\n",
    "\n",
    "x_test = test_data.fillna(0)\n",
    "\n",
    "# 打乱数据\n",
    "# train_data = train_data.sample(frac=1.0)\n",
    "# test_data = x_test.sample(frac=1.0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.sort_values([\"label\"],inplace=True)\n",
    "\n",
    "train_data = train_data[900000:]\n",
    "train_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train_data.head()\n",
    "\n",
    "\n",
    "## 删除  普通消费\n",
    "train_data = train_data[(train_data[\"label\"] != -1)]\n",
    "print(train_data[\"label\"].unique())\n",
    "\n",
    "train_label = train_data[\"label\"]\n",
    "train_data = train_data.drop(\"label\", axis=1)\n",
    "\n",
    "\n",
    "train_data,val_data, train_label ,val_label = train_test_split(train_data,train_label,test_size=0.3,random_state=6)\n",
    "\n",
    "print(\"划分后\")\n",
    "print(\"train %d : 验证 %d\"%(len(train_label),len(val_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(train_label)\n",
    "\n",
    "tmp[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练集，验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "S=StandardScaler()\n",
    "\n",
    "S.fit(train_data)\n",
    "\n",
    "x_train_stand = S.transform(train_data)\n",
    "\n",
    "x_val_stand = S.transform(val_data)\n",
    "\n",
    "\n",
    "print(x_train_stand[1])\n",
    "x_test_stand=S.transform(test_data.drop([\"label\"],axis=1))\n",
    "\n",
    "\n",
    "print(\"----train-----\")\n",
    "model = SGDClassifier(#lambda:\n",
    "    loss='log',\n",
    "    penalty='elasticnet',\n",
    "    fit_intercept=True,\n",
    "    max_iter=100,\n",
    "    shuffle=True,\n",
    "    alpha = 0.01,\n",
    "    l1_ratio = 0.01,\n",
    "    n_jobs=1,\n",
    "    class_weight=None\n",
    ")\n",
    "model.fit(x_train_stand, train_label)\n",
    "print(\"end\")\n",
    "# fpr, tpr, thresholds = roc_curve(val_label, prediction[:,1], pos_label=1)\n",
    "# print(\"auc:\",auc(fpr, tpr))\n",
    "\n",
    "\n",
    "# auc_score1 = myAUC(val_label,prediction[:,0])\n",
    "\n",
    "# print(Log.score(x_val_stand,val_label))\n",
    "# print(auc_score1)\n",
    "\n",
    "# result=pd.DataFrame({'PassengerId':test_data.index,'Survived':res[:,0]})  #这里需要注意把prediction的数据转换成Int型不然系统判定不了，得分会为0 \n",
    "# result.to_csv('../ali-data/result.csv',index=False) #设置不输出Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 预测以及结果评价\n",
    "print(model.score(x_val_stand, val_label))\n",
    "\n",
    "# val = val_data.copy()\n",
    "# val['pred_prob'] = model.predict_proba(x_val_stand)[:,1]\n",
    "# validgroup = val.groupby(['Coupon_id'])\n",
    "# aucs = []\n",
    "# for i in validgroup:\n",
    "#     tmpdf = i[1] \n",
    "#     if len(tmpdf['label'].unique()) != 2:\n",
    "#         continue\n",
    "#     fpr, tpr, thresholds = roc_curve(tmpdf['label'], tmpdf['pred_prob'], pos_label=1)\n",
    "#     aucs.append(auc(fpr, tpr))\n",
    "# print(np.average(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre = model.predict_proba(x_test_stand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction for submission\n",
    "y_test_pred = model.predict_proba(x_test_stand)\n",
    "dftest1 = df_test[['User_id','Coupon_id','Date_received']].copy()\n",
    "dftest1['label'] = y_test_pred[:,1]\n",
    "dftest1.to_csv('../ali-data/submit1.csv', index=False, header=False)\n",
    "dftest1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dftest1 = df_test[['User_id','Coupon_id','Date_received']].copy()\n",
    "dftest1['label'] = res[:,1]\n",
    "dftest1.to_csv('../ali-data/submit1.csv', index=False, header=False)\n",
    "dftest1.head(10)\n",
    "\n",
    "# avgAUC calculation\n",
    "vg = dftest1.groupby(['Coupon_id'])\n",
    "aucs = []\n",
    "for i in vg:\n",
    "    tmpdf = i[1] \n",
    "    if len(tmpdf['label'].unique()) != 2:\n",
    "        continue\n",
    "    fpr, tpr, thresholds = roc_curve(tmpdf['label'], tmpdf['pred_prob'], pos_label=1)\n",
    "    aucs.append(auc(fpr, tpr))\n",
    "print(np.average(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from math import ceil\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "\n",
    "\n",
    "def train_xgb(dataset12, dataset3):\n",
    "    predict_dataset = dataset3[['User_id', 'Coupon_id', 'Date_received']].copy()\n",
    "    predict_dataset.Date_received = pd.to_datetime(predict_dataset.Date_received, format='%Y-%m-%d')\n",
    "    predict_dataset.Date_received = predict_dataset.Date_received.dt.strftime('%Y%m%d')\n",
    "\n",
    "    # 将数据转化为dmatric格式\n",
    "    dataset12_x = dataset12.drop(\n",
    "        columns=['User_id', 'Merchant_id', 'Discount_rate', 'Date_received', 'discount_rate_x', 'discount_rate_y',\n",
    "                 'Date', 'Coupon_id', 'label'], axis=1)\n",
    "    dataset3_x = dataset3.drop(\n",
    "        columns=['User_id', 'Merchant_id', 'Discount_rate', 'Date_received', 'discount_rate_x', 'discount_rate_y',\n",
    "                 'Coupon_id'], axis=1)\n",
    "\n",
    "    train_dmatrix = xgb.DMatrix(dataset12_x, label=dataset12.label)\n",
    "    predict_dmatrix = xgb.DMatrix(dataset3_x)\n",
    "\n",
    "    # xgboost模型训练\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective': 'binary:logistic',\n",
    "              'eval_metric': 'auc',\n",
    "              'gamma': 0.1,\n",
    "              'min_child_weight': 1.1,\n",
    "              'max_depth': 5,\n",
    "              'lambda': 10,\n",
    "              'subsample': 0.7,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'colsample_bylevel': 0.7,\n",
    "              'eta': 0.01,\n",
    "            #   'tree_method': 'gpu_hist',\n",
    "            #   'n_gpus': '-1',\n",
    "              'seed': 0,\n",
    "              'nthread': cpu_jobs,\n",
    "            #   'predictor': 'gpu_predictor'\n",
    "              }\n",
    "\n",
    "    # 使用xgb.cv优化num_boost_round参数\n",
    "    cvresult = xgb.cv(params, train_dmatrix, num_boost_round=10000, nfold=2, metrics='auc', seed=0, callbacks=[\n",
    "        xgb.callback.print_evaluation(show_stdv=False),\n",
    "        xgb.callback.early_stop(50)\n",
    "    ])\n",
    "    num_round_best = cvresult.shape[0] - 1\n",
    "    print('Best round num: ', num_round_best)\n",
    "\n",
    "    # 使用优化后的num_boost_round参数训练模型\n",
    "    watchlist = [(train_dmatrix, 'train')]\n",
    "    model = xgb.train(params, train_dmatrix, num_boost_round=num_round_best, evals=watchlist)\n",
    "\n",
    "    model.save_model('./2xgbmodel')\n",
    "    params['predictor'] = 'cpu_predictor'\n",
    "    model = xgb.Booster(params)\n",
    "    model.load_model('./1xgbmodel')\n",
    "\n",
    "    # predict test set\n",
    "    dataset3_predict = predict_dataset.copy()\n",
    "    dataset3_predict['label'] = model.predict(predict_dmatrix)\n",
    "\n",
    "    # 标签归一化\n",
    "    dataset3_predict.label = MinMaxScaler(copy=True, feature_range=(0, 1)).fit_transform(\n",
    "        dataset3_predict.label.values.reshape(-1, 1))\n",
    "    dataset3_predict.sort_values(by=['Coupon_id', 'label'], inplace=True)\n",
    "    dataset3_predict.to_csv(\"./xgb_preds.csv\", index=None, header=None)\n",
    "    print(dataset3_predict.describe())\n",
    "\n",
    "    # 在dataset12上计算auc\n",
    "    # model = xgb.Booster()\n",
    "    # model.load_model('train_dir_2/xgbmodel')\n",
    "\n",
    "#     temp = dataset12[['Coupon_id', 'label']].copy()\n",
    "#     temp['pred'] = model.predict(xgb.DMatrix(dataset12_x))\n",
    "#     temp.pred = MinMaxScaler(copy=True, feature_range=(0, 1)).fit_transform(temp['pred'].values.reshape(-1, 1))\n",
    "#     print(myauc(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3a790438adb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_xgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_xgb(train_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
